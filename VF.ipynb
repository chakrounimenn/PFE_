{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b54643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ea7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Suppression des caractères spéciaux\n",
    "    text = re.sub(r\"[^a-zA-ZÀ-ÿ0-9\\s]\", \"\", text)\n",
    "    \n",
    "    # Suppression des espaces après la suppression des caractères spéciaux\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Suppression de la ponctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    # Suppression des chiffres\n",
    "    text = re.sub(r\"\\d\", \"\", text)\n",
    "    text = text.replace('&', '')\n",
    "    # Convertir le texte en minuscules\n",
    "    text = text.lower()\n",
    "    # Remplacer les doubles espaces par un seul espace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c12841e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charger_fichiers_csv(chemin):\n",
    "    # Obtenir la liste des fichiers dans le chemin spécifié\n",
    "    fichiers = os.listdir(chemin)\n",
    "    \n",
    "    dataframes = []\n",
    "    \n",
    "    # Parcourir chaque fichier dans la liste\n",
    "    for fichier in fichiers:\n",
    "        if fichier.endswith('.csv'):  # Vérifier si le fichier a l'extension .csv\n",
    "            chemin_fichier = os.path.join(chemin, fichier)  # Chemin complet du fichier\n",
    "            \n",
    "            # Charger le fichier CSV dans un DataFrame et l'ajouter à la liste\n",
    "            df = pd.read_csv(chemin_fichier)\n",
    "            dataframes.append(df)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db4f02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_info_dataframe(df):\n",
    "    # Afficher la forme du DataFrame\n",
    "    print(\"Shape du DataFrame :\", df.shape)\n",
    "    \n",
    "    # Afficher le contenu du DataFrame (les 5 premières lignes)\n",
    "    print(\"Contenu du DataFrame :\")\n",
    "    print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7adf9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_categories(df):\n",
    "    mots_cles = ['pflege', 'makeup', 'sonne', 'körper', 'düfte', 'haare', 'gesicht', 'gesundheit','lebensmittel','tier','baby spielzeug','home lifestyle','parfum','apotheke gesundheit','haushalt','ernährung']\n",
    "    \n",
    "    df['category'] = df['category'].astype(str)\n",
    "    #df = df.dropna(subset=['category'])\n",
    "    #df = df.dropna(subset=['description'])\n",
    "    \n",
    "    def trouver_mot_cle(categorie, mots_cles):\n",
    "        for mot_cle in mots_cles:\n",
    "            if mot_cle in categorie.lower():\n",
    "                return mot_cle\n",
    "        return None\n",
    "\n",
    "    df['category'] = df['category'].astype(str).apply(lambda x: trouver_mot_cle(x, mots_cles))\n",
    "\n",
    "    df_grouped = df.groupby('category')['category'].apply(list).reset_index(name='categories_groupes')\n",
    "\n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0770bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrouper_categories(df):\n",
    "    mots_cles = ['pflege', 'makeup', 'sonne', 'körper', 'düfte', 'haare', 'gesicht', 'gesundheit']\n",
    "\n",
    "    def trouver_mot_cle(categorie, mots_cles):\n",
    "        for mot_cle in mots_cles:\n",
    "            if mot_cle in categorie.lower():\n",
    "                return mot_cle\n",
    "        return None\n",
    "\n",
    "    df['category'] = df['category'].astype(str).apply(lambda x: trouver_mot_cle(x, mots_cles))\n",
    "\n",
    "    df_grouped = df.groupby('category')['category'].apply(list).reset_index(name='categories_groupes')\n",
    "\n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68680291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -Vectorisation des données \n",
    "#- la recherche des meilleurs paramètres à l'aide de la validation croisée\n",
    "#-entraînement du modèle LinearSVC\n",
    "#-la prédiction des labels sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5963e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_svc_model(df):\n",
    "    # Diviser les données en ensembles d'entraînement et de test (par exemple, 80% pour l'entraînement, 20% pour le test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['description'], df['category'], test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train = X_train.apply(preprocess_text)\n",
    "    X_test = X_test.apply(preprocess_text)\n",
    "    \n",
    "    # Créer une instance de Tf-idfVectorizer ou CountVectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    \n",
    "    # Appliquer la vectorisation aux données d'entraînement et de test\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "    X_test_count = count_vectorizer.transform(X_test)\n",
    "    \n",
    "    # Définir une pipeline avec une vectorisation Tfidf et un classificateur LinearSVC\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', LinearSVC())\n",
    "    ])\n",
    "    \n",
    "    # Définir les paramètres à tester pour le classificateur LinearSVC\n",
    "    parameters = {\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__max_iter': [100, 500, 1000]\n",
    "    }\n",
    "    \n",
    "    # Cross validation\n",
    "    # Utiliser la validation croisée pour trouver les meilleurs paramètres\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Afficher les meilleurs paramètres et le score obtenu sur l'ensemble de validation\n",
    "    print(\"Meilleurs paramètres : \")\n",
    "    print(grid_search.best_params_)\n",
    "    print(\"Score sur l'ensemble de validation : \")\n",
    "    print(grid_search.best_score_)\n",
    "    \n",
    "    # Créer une instance du classificateur SVM à noyau linéaire avec les meilleurs paramètres trouvés\n",
    "    best_clf = LinearSVC(C=grid_search.best_params_['clf__C'], max_iter=grid_search.best_params_['clf__max_iter'])\n",
    "    \n",
    "    # Entraîner le modèle sur l'ensemble d'entraînement\n",
    "    best_clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Prédire les labels sur l'ensemble de test\n",
    "    predictions_SVM = best_clf.predict(X_test_tfidf)\n",
    "    \n",
    "    return best_clf, X_test_tfidf, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30067bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_model(best_clf, X_test_tfidf, y_test, model_path):\n",
    "    # Faire des prédictions sur l'ensemble de test\n",
    "    y_pred = best_clf.predict(X_test_tfidf)\n",
    "\n",
    "    # Calculer la précision\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    # Calculer le score F1\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Score F1 sur l'ensemble de test:\", f1)\n",
    "\n",
    "    # Calculer l'accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy sur l'ensemble de test:\", accuracy)\n",
    "\n",
    "    # Enregistrer le modèle\n",
    "    joblib.dump(best_clf, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e08f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [category, categories_groupes]\n",
      "Index: []\n",
      "La colonne 'description' n'est pas présente dans le DataFrame.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Chemin vers les fichiers CSV\n",
    "    chemin = 'C:/Users/infoMix/Desktop/PFE/Deutch'\n",
    "    \n",
    "    # Charger les fichiers CSV dans un DataFrame\n",
    "    df = charger_fichiers_csv(chemin)\n",
    "    \n",
    "    # Regrouper les catégories\n",
    "    df = group_categories(df)\n",
    "    print(df)\n",
    "    \n",
    "    # Vérifier si la colonne 'description' est toujours présente dans le DataFrame\n",
    "    if 'description' not in df.columns:\n",
    "        print(\"La colonne 'description' n'est pas présente dans le DataFrame.\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6e1a175",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13748\\1309667155.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06354527",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (844393206.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\infoMix\\AppData\\Local\\Temp\\ipykernel_13748\\844393206.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    best_clf, X_test_tfidf, y_test = train_linear_svc_model(df)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle LinearSVC\n",
    "    best_clf, X_test_tfidf, y_test = train_linear_svc_model(df)\n",
    "    \n",
    "    # Évaluer le modèle et enregistrer\n",
    "    model_path = 'model.pkl'\n",
    "    evaluate_and_save_model(best_clf, X_test_tfidf, y_test, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92daf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150183d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab7c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608802cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8474309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a54de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817bf6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7416d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01843047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db8068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4290b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
